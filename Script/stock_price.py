# -*- coding: utf-8 -*-
"""Stock_Price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15E2wq2e-fzHuwrqY7ro__GAcD57459Fs

<h1 align='center'><b><u>Stock Prediction on Real-time Data</u></b></h1>

- Import Pandas DataReader Module (*You can also find the complete Documentation <a href='https://pandas-datareader.readthedocs.io/en/latest/'>here</a>*)
"""

# !pip install pandas-datareader
import pandas_datareader as pdr

"""- Now for Collecting the Real-time Data we use the Tiingo API (<a href='https://api.tiingo.com/'>here</a>) 
- Follow the steps mentioned in the following file <a href='https://github.com/VetlaPavanKalyan/Stock-Price-Prediction/blob/main/API%20Key%20Generation.md'>here</a>
"""

key = '' # Update this cell with your API Key

"""- Now for our Prediction we are using **GOOGLE** Stocks Prediciton
- **GOOGLE** 's STOCK ID according to Tiingo is ```GOOGL```
- For Collecting the Data we use ```get_data_tiingo()``` method
"""

df = pdr.get_data_tiingo('GOOGL', api_key=key)

"""- Create a DataFrame on the Data we Collected"""

df.to_csv('./data.csv')

import pandas as pd
df = pd.read_csv('./data.csv')

"""- Exploratory Data Analysis"""

df.head()

df.tail()

"""- We are using the Stock Closing Price (```close```) for Prediciton."""

df1 = df['close']

import matplotlib.pyplot as plt
plt.plot(df1)

import numpy as np

"""- Our Closing Stock Price is"""

print(df1)

"""- For Predictons we use ```LSTM``` 's
and also since ```LSTM``` 's are sensitive to Data,
- We need to Scale our Data before predicitons.
- For Now we are using ```MinMaxScaler()```
"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler(feature_range=(0, 1))
df2 = scaler.fit_transform(np.array(df1).reshape(-1, 1))

df2

"""- Let's Set our Training Data be ```65 %``` of the actual data size and Testing Data be remaining ```35 %``` of the actual data size. """

training_size = int(len(df2)*0.65)
test_size = len(df2) - training_size
training_size, test_size

train_data, test_data = df2[: training_size], df2[training_size: ]

train_data.shape, test_data.shape

"""- After we prepared our data, we need to prepare independent (```X```) and dependent (```Y```) features.
- We know that the each (```Y```) is dependent on every (```X```).
- Consider the following data, 
```
data = [t1, t2, t3, t4, t5, ...]
```
"""

def create_dataset(dataset, time_step=1):
    dataX, dataY = [], []
    for i in range(len(dataset) - time_step - 1):
        a = dataset[i: (i+time_step), 0]
        dataX.append(a)
        dataY.append(dataset[i+time_step][0])
    return np.array(dataX), np.array(dataY)

"""- Each Time step t<sub>i</sub> depends on t<sub>i-1</sub> Time step.
- We Create our Data for predicitons based on the following example:
- ```X1, X2, X3 -> X4 (Y1)```
- ```X2, X3, X4 -> X5 (Y2)```
and so on...
"""

time_step = 100
x_train, y_train = create_dataset(train_data, time_step)
x_test, y_test = create_dataset(test_data, time_step)

x_train.shape, y_train.shape, x_test.shape, y_test.shape

X_train, X_test = x_train.reshape(x_train.shape[0], x_train.shape[1], 1), x_test.reshape(x_test.shape[0], x_test.shape[1], 1)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM

"""- We are using a ```Stacked LSTM``` as our Model"""

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))
model.add(LSTM(50, return_sequences=True))
model.add(LSTM(50))
model.add(Dense(1))
model.compile('adam', 'mse')

"""- Model Structure"""

model.summary()

"""- Fit our Training Data with ```batch size = 64``` and ```epochs = 100```"""

model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=64,verbose=1)

"""- Let's predict our ```train``` and ```test``` data"""

train_predict=model.predict(X_train)
test_predict=model.predict(X_test)

"""- Let's Inverse the Scaled data using ```inverse_transform()``` from the ```scaler``` object"""

train_predict=scaler.inverse_transform(train_predict)
test_predict=scaler.inverse_transform(test_predict)

"""- Compute the ```RMSE``` Score"""

from sklearn.metrics import mean_squared_error
mean_squared_error(y_train, train_predict, squared=False), mean_squared_error(y_test, test_predict, squared=False)

"""- Let's Visulaize our Predictions along side with the Actual Data"""

look_back=time_step
trainPredictPlot = np.empty_like(df2)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict
# shift test predictions for plotting
testPredictPlot = np.empty_like(df2)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(train_predict)+(look_back*2)+1:len(df2)-1, :] = test_predict
# plot baseline and predictions
plt.plot(scaler.inverse_transform(df2))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()

"""- See the Predicted and Actual Data are Nearly Equal"""

len(test_data)

"""- Now Let's Predict the Future 30 Days Data
- Let's take last 100 Days Data for our future 30 days prediction.
"""

x_input = test_data[341:].reshape(1, -1)
x_input.shape

temp_input=list(x_input)
temp_input=temp_input[0].tolist()

temp_input

"""- Now let's predict the Data for Future 30 days"""

lst_output=[]
n_steps=100
i=0
while(i<30):
    
    if(len(temp_input)>100):
        #print(temp_input)
        x_input=np.array(temp_input[1:])
        print("day-{} input: \n{}".format(i+1,x_input))
        x_input=x_input.reshape(1,-1)
        x_input = x_input.reshape((1, n_steps, 1))
        #print(x_input)
        yhat = model.predict(x_input, verbose=0)
        print("day-{} output: \n{}".format(i+1,yhat))
        temp_input.extend(yhat[0].tolist())
        temp_input=temp_input[1:]
        #print(temp_input)
        lst_output.extend(yhat.tolist())
        i=i+1
    else:
        x_input = x_input.reshape((1, n_steps,1))
        yhat = model.predict(x_input, verbose=0)
        print(yhat[0])
        temp_input.extend(yhat[0].tolist())
        print(len(temp_input))
        lst_output.extend(yhat.tolist())
        i=i+1
    

print(lst_output)

day_new=np.arange(1,101)
day_pred=np.arange(101,131)

len(df2)

"""- Now Let's visualize the future Prediciton.  """

plt.plot(day_new,scaler.inverse_transform(df2[1159:]))
plt.plot(day_pred,scaler.inverse_transform(lst_output))

"""- Now Attach our prediction to the Actual Data and Visualize"""

df3=df2.tolist()
df3.extend(lst_output)
plt.plot(df3[1200:])

"""- Visualizing the Whole attached new Data."""

df3=scaler.inverse_transform(df3).tolist()
plt.plot(df3)